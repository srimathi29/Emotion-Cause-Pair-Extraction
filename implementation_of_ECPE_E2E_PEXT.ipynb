{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZqb25-5aLay"
      },
      "source": [
        "From this repo https://github.com/Aaditya-Singh/E2E-ECPE/tree/main which talks about this paper https://aaditya-singh.github.io/data/ECPE.pdf An End-to-End Network for Emotion-Cause Pair Extraction\n",
        "Aaditya Singh∗† Shreeshail Hingane† Saim Wani† Ashutosh Modi\n",
        "\n",
        "\n",
        "This github explains the dataset : https://github.com/naveed92/ecpe_datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THis colab is implementation of https://github.com/NVJKKartik/Emo_Cause_Pair/blob/main/E2E_PextE.py\n"
      ],
      "metadata": {
        "id": "lIytHadcvKy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eVm7Hdk_KOI",
        "outputId": "00c17641-a3ac-4477-ee06-107d74e9ff88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py2kvEJ3dFIr",
        "outputId": "60be3213-3ff8-4e03-b10b-3075d8defc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/E2E-ECPE-main'\n",
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "save_dir = \"./save\"\n",
        "\n",
        "# Check if the directory exists, and if not, create it\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "    # Define the directory path\n",
        "dir = \"./data\"\n",
        "\n",
        "# Check if the directory exists, and if not, create it\n",
        "if not os.path.exists(dir):\n",
        "    os.makedirs(dir)"
      ],
      "metadata": {
        "id": "z4uz2bNrbW18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drivePath = '/content/drive/My Drive/NLPproj/ECPESemeval'\n",
        "traindatasetPath = drivePath + \"/Subtask_1_train.json\"\n",
        "testdatasetPath = drivePath + \"/Subtask_1_test.json\""
      ],
      "metadata": {
        "id": "6OpFMyC11UFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "# Check if GPU is available and select appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ8G38xr2M9n",
        "outputId": "58bebf81-caa0-4235-bcbc-795cb3eee26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8xDncK-2Rgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d96eb2a9-3d62-4028-ebcb-cf503b65ba12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/NLPproj/ECPESemeval/Subtask_1_train.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-932756fcc9eb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindatasetPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/NLPproj/ECPESemeval/Subtask_1_train.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "utils> funcs.py"
      ],
      "metadata": {
        "id": "7wtuZfyLbJGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################ IMPORT ##########################################################\n",
        "import sys, os\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "############################################ EMBEDDING LOOKUP ################################################\n",
        "def embedding_lookup(word_embedding, x):\n",
        "    '''\n",
        "    input(s) shape: [num_words, embedding_dim], [batch_size, doc_len, sen_len]\n",
        "    output shape: [batch_size, doc_len, sen_len, embedding_dim]\n",
        "    '''\n",
        "    # x = F.embedding(torch.from_numpy(x).type(torch.LongTensor), torch.from_numpy(word_embedding))\n",
        "    x = F.embedding(x.type(torch.LongTensor), word_embedding).to(device)\n",
        "    return x\n",
        "\n",
        "############################################ ATTENTION #######################################################\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, n_hidden, sen_len):\n",
        "        super(Attention, self).__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "        self.sen_len = sen_len\n",
        "        self.linear1 = nn.Linear(n_hidden*2, n_hidden*2)\n",
        "        self.linear2 = nn.Linear(n_hidden*2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        input shape: [batch_size * doc_len, sen_len, 2 * n_hidden]\n",
        "        output shape: [batch_size * doc_len, 2 * n_hidden]\n",
        "        '''\n",
        "        x_tmp = x.reshape(-1, self.n_hidden*2)\n",
        "        # x_tmp is of shape (batch_size * doc_len * sen_len, 2 * n_hidden)\n",
        "        u = torch.tanh(self.linear1(x_tmp))\n",
        "        # u is of shape (batch_size * doc_len * sen_len, 2 * n_hidden)\n",
        "        alpha = self.linear2(u)\n",
        "        # alpha is of shape (batch_size * doc_len * sen_len, 1)\n",
        "        alpha = F.softmax(alpha.reshape(-1, 1, self.sen_len), dim = -1)\n",
        "        # alpha is of shape (batch_size * doc_len, 1, sen_len)\n",
        "        x = torch.matmul(alpha, x).reshape(-1, self.n_hidden*2)\n",
        "        # x is of shape (batch_size * doc_len, 2 * n_hidden)\n",
        "        return x\n",
        "\n",
        "############################################## GET MASK ######################################################\n",
        "def getmask(y, doc_len):\n",
        "    '''\n",
        "    input(s) shape: [max_doc_len * max_doc_len, 2], doc_len\n",
        "    output shape: [doc_len * doc_len, 2]\n",
        "    '''\n",
        "    i = 0; j = 0\n",
        "    max_doc_len = int(np.sqrt(y.shape[0]))\n",
        "    y_mask = torch.zeros(doc_len * doc_len, 2)\n",
        "    while j < doc_len**2:\n",
        "        y_mask[j : j+doc_len] = y[i : i+doc_len]\n",
        "        j += doc_len; i += max_doc_len\n",
        "    return y_mask\n",
        "\n",
        "############################################ LOSS FUNCTION ###################################################\n",
        "class ce_loss_aux(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ce_loss_aux, self).__init__()\n",
        "\n",
        "    def forward(self, y_true, y_pred, doc_len, diminish_factor=1.0):\n",
        "        '''\n",
        "        input(s) shape: [batch_size, doc_len, 2]\n",
        "        output shape: []\n",
        "        '''\n",
        "        y_true = y_true.to('cpu'); y_pred = y_pred.to('cpu')\n",
        "        loss = torch.autograd.Variable(torch.zeros([], dtype=torch.double))\n",
        "        for i in range(len(doc_len)):\n",
        "            y_true_masked = y_true[i, :doc_len[i]]; y_pred_masked = y_pred[i, :doc_len[i]].double()\n",
        "            y_pred_masked_ones = torch.log(y_pred_masked[:, 1][y_true_masked[:, 1]==1.])\n",
        "            y_pred_masked_zeros = torch.log(y_pred_masked[:, 0][y_true_masked[:, 0]==1.])\n",
        "            pos_loss = -torch.sum(y_pred_masked_ones)\n",
        "            neg_loss = -torch.sum(y_pred_masked_zeros)*diminish_factor\n",
        "            loss += pos_loss + neg_loss\n",
        "            # loss -= torch.sum(y_true_masked * torch.log(y_pred_masked))\n",
        "        loss /= torch.sum(doc_len)\n",
        "        loss.requires_grad_(True)\n",
        "        return loss\n",
        "\n",
        "class ce_loss_pair(torch.nn.Module):\n",
        "    def __init__(self, diminish_factor):\n",
        "        super(ce_loss_pair, self).__init__()\n",
        "        self.diminish_factor = diminish_factor\n",
        "\n",
        "    def forward(self, y_true, y_pred, doc_len):\n",
        "        '''\n",
        "        input(s) shape: [batch_size, doc_len, 2]\n",
        "        output shape: []\n",
        "        '''\n",
        "        y_true = y_true.to('cpu'); y_pred = y_pred.to('cpu')\n",
        "        loss = torch.autograd.Variable(torch.zeros([], dtype=torch.double))\n",
        "        for i in range(len(doc_len)):\n",
        "            y_true_masked = getmask(y_true[i].clone(), doc_len[i])\n",
        "            y_pred_masked = getmask(y_pred[i].clone(), doc_len[i]).double()\n",
        "            y_pred_masked_ones = torch.log(y_pred_masked[:, 1][y_true_masked[:, 1]==1])\n",
        "            pos_loss = -torch.sum(y_pred_masked_ones)\n",
        "            y_pred_masked_zeros = torch.log(y_pred_masked[:, 0][y_true_masked[:, 0]==1])\n",
        "            neg_loss = -torch.sum(y_pred_masked_zeros)\n",
        "            ############################## Give less weight to -ve examples ##############################\n",
        "            neg_loss *= self.diminish_factor\n",
        "            loss += pos_loss + neg_loss\n",
        "            # y_pred_masked needs to be of dtype double\n",
        "        loss /= torch.sum(doc_len)\n",
        "        loss.requires_grad_(True)\n",
        "        return loss\n",
        "\n",
        "########################################## CREATE PAIRS ######################################################\n",
        "def create_pairs(x1, x2):\n",
        "    '''\n",
        "    input(s) shape: [batch_size, doc_len, 2 * n_hidden]\n",
        "    output shape: [batch_size, doc_len * doc_len, 4 * n_hidden]\n",
        "    '''\n",
        "    iters = 0\n",
        "    for i in range(x1.shape[1]):\n",
        "        for j in range(x2.shape[1]):\n",
        "            x3_tmp = torch.cat([x1[:, i, :], x2[:, j, :]], dim=1).unsqueeze(1)\n",
        "            if iters :\n",
        "                x3 = torch.cat([x3, x3_tmp], dim=1)\n",
        "            else :\n",
        "                x3 = x3_tmp\n",
        "            iters += 1\n",
        "    return x3\n",
        "\n",
        "############################################ DATA GEN ########################################################\n",
        "def batch_index(length, batch_size, test=False):\n",
        "    index = list(range(length))\n",
        "    if test == False:\n",
        "        np.random.shuffle(index)\n",
        "    for i in range(int((length + batch_size -1)/batch_size)):\n",
        "        ret = index[i * batch_size : (i + 1) * batch_size]\n",
        "        if test == False and len(ret) < batch_size : break\n",
        "        yield ret\n",
        "\n",
        "def get_batch_data_pair(x, sen_len, doc_len, y_position, y_cause, y_pair, distance, batch_size, test=False):\n",
        "    for index in batch_index(len(y_cause), batch_size, test):\n",
        "        feed_list = [x[index], sen_len[index], doc_len[index], y_position[index], y_cause[index], \\\n",
        "        y_pair[index], distance[index]]\n",
        "        yield feed_list, len(index)\n",
        "\n",
        "###################################### ACCURACY, PRECISION, RECALL, F1 #######################################\n",
        "def metrics(y_true, y_pred):\n",
        "    y_true_cpu = y_true.cpu().numpy()\n",
        "    y_pred_cpu = y_pred.cpu().numpy()\n",
        "    true_pos = np.sum((y_true_cpu == 1.) & (y_pred_cpu == 1.))\n",
        "    true_neg = np.sum((y_true_cpu == 0.) & (y_pred_cpu == 0.))\n",
        "    false_pos = np.sum((y_true_cpu == 0.) & (y_pred_cpu == 1.))\n",
        "    false_neg = np.sum((y_true_cpu == 1.) & (y_pred_cpu == 0.))\n",
        "    epsilon = 1e-9\n",
        "    acc = (true_pos + true_neg) / (false_pos + false_neg + true_pos + true_neg + epsilon)\n",
        "    p = true_pos / (false_pos + true_pos + epsilon)\n",
        "    r = true_pos / (false_neg + true_pos + epsilon)\n",
        "    f1 = 2 * p * r / (p + r + epsilon)\n",
        "    return acc, p, r, f1\n",
        "\n",
        "def acc_prf_aux(pred_y, true_y, doc_len, average='weighted'):\n",
        "    _, true_indices = torch.max(true_y, 2)\n",
        "    _, pred_indices = torch.max(pred_y, 2)\n",
        "    true_indices_masked = []\n",
        "    pred_indices_masked = []\n",
        "    for i in range(len(doc_len)):\n",
        "        true_indices_masked.extend(true_indices[i, :doc_len[i]])\n",
        "        pred_indices_masked.extend(pred_indices[i, :doc_len[i]])\n",
        "\n",
        "    true_indices_masked = torch.tensor(true_indices_masked).to(true_y.device)\n",
        "    pred_indices_masked = torch.tensor(pred_indices_masked).to(pred_y.device)\n",
        "\n",
        "    acc, p, r, f1 = metrics(true_indices_masked, pred_indices_masked)\n",
        "    return acc, p, r, f1\n",
        "\n",
        "def acc_prf_pair(pred_y, true_y, doc_len):\n",
        "    true_indices_masked_list = []\n",
        "    pred_indices_masked_list = []\n",
        "\n",
        "    for i in range(len(doc_len)):\n",
        "        true_y_masked = getmask(true_y[i].clone(), doc_len[i])\n",
        "        pred_y_masked = getmask(pred_y[i].clone(), doc_len[i])\n",
        "\n",
        "        _, true_indices_masked = torch.max(true_y_masked, 1)\n",
        "        _, pred_indices_masked = torch.max(pred_y_masked, 1)\n",
        "\n",
        "        true_indices_masked_list.extend(true_indices_masked.tolist())  # Convert to Python list\n",
        "        pred_indices_masked_list.extend(pred_indices_masked.tolist())  # Convert to Python list\n",
        "\n",
        "    # Now you can convert these lists to tensors when needed\n",
        "    true_indices_masked_tensor = torch.tensor(true_indices_masked_list).to(device)\n",
        "    pred_indices_masked_tensor = torch.tensor(pred_indices_masked_list).to(device)\n",
        "\n",
        "    acc, p, r, f1 = metrics(true_indices_masked_tensor, pred_indices_masked_tensor)\n",
        "    return acc, p, r, f1"
      ],
      "metadata": {
        "id": "Jp8dTrp3bKTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utils>prepare_data.py\n"
      ],
      "metadata": {
        "id": "Suzhkr7EbpoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################ IMPORT ##########################################################\n",
        "import sys, os\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "############################################ LOAD W2V EMBEDDING ###############################################\n",
        "def load_w2v(embedding_dim, embedding_dim_pos, train_file_path, embedding_path):\n",
        "    print('\\nload embedding...')\n",
        "\n",
        "    words = []\n",
        "    inputFile1 = open(train_file_path, 'r',encoding='cp1252')\n",
        "    for line in inputFile1.readlines():\n",
        "        line = line.strip().split(',')\n",
        "        emotion, clause = line[2], line[-2]\n",
        "        words.extend(emotion.lower().split() + clause.lower().split())\n",
        "        # words extended by ['happy','the','thief','was','caught']\n",
        "\n",
        "    words = set(words) # Collection of all unique words\n",
        "    word_idx = dict((c, k + 1) for k, c in enumerate(words)) # Each word and its position\n",
        "    word_idx_rev = dict((k + 1, c) for k, c in enumerate(words)) # Each word and its position\n",
        "\n",
        "    w2v = {}\n",
        "    inputFile2 = open(embedding_path, 'r')\n",
        "    inputFile2.readline()\n",
        "    for line in inputFile2.readlines():\n",
        "        line = line.strip().split(' ')\n",
        "        w, ebd = line[0], line[1:]\n",
        "        w2v[w] = ebd\n",
        "\n",
        "    embedding = [list(np.zeros(embedding_dim))]\n",
        "    hit = 0\n",
        "    for item in words:\n",
        "        if item in w2v:\n",
        "            vec = list(map(float, w2v[item]))\n",
        "            hit += 1\n",
        "        else:\n",
        "            vec = list(np.random.rand(embedding_dim) / 5. - 0.1)\n",
        "            # Randomly take from the uniform distribution [-0.1, 0.1]\n",
        "        embedding.append(vec)\n",
        "    print('w2v_file: {}\\nall_words: {} hit_words: {}'.format(embedding_path, len(words), hit))\n",
        "    # add a noisy embedding in the end for out of vocabulary words\n",
        "    embedding.extend([list(np.random.rand(embedding_dim) / 5. - 0.1)])\n",
        "\n",
        "    embedding_pos = [list(np.zeros(embedding_dim_pos))]\n",
        "    embedding_pos.extend([list(np.random.normal(loc=0.0, scale=0.1, size=embedding_dim_pos)) \\\n",
        "        for i in range(200)])\n",
        "    embedding, embedding_pos = np.array(embedding), np.array(embedding_pos)\n",
        "\n",
        "    print(\"embedding.shape: {} embedding_pos.shape: {}\".format(embedding.shape, embedding_pos.shape))\n",
        "    print(\"load embedding done!\\n\")\n",
        "    return word_idx_rev, word_idx, embedding, embedding_pos\n",
        "\n",
        "############################################ LOAD DATA PAIR STEP ##############################################\n",
        "def load_data_pair(input_file, word_idx, max_doc_len=75, max_sen_len=45):\n",
        "    print('load data_file: {}'.format(input_file))\n",
        "    pair_id_all, y_emotion, y_cause, y_pair, x, sen_len, doc_len, distance = [], [], [], [], [], [], [], []\n",
        "    n_cut = 0\n",
        "    inputFile = open(input_file, 'r',encoding='cp1252')\n",
        "\n",
        "    while True:\n",
        "        line = inputFile.readline()\n",
        "        if line == '':\n",
        "            break\n",
        "\n",
        "        line = line.strip().split()\n",
        "        doc_id = int(line[0])\n",
        "        d_len = int(line[1])\n",
        "\n",
        "        # Skipping lines if the document length is greater than or equal to max_doc_len\n",
        "        if d_len >= max_doc_len:\n",
        "            for i in range(d_len + 1):\n",
        "                line = inputFile.readline().strip().split(',')\n",
        "            continue\n",
        "\n",
        "        pairs_str = inputFile.readline().strip()\n",
        "\n",
        "        # Check if pairs_str is not empty\n",
        "        if pairs_str:\n",
        "            pairs = eval(pairs_str)\n",
        "\n",
        "            # Always convert pairs to a list of lists for consistency\n",
        "            if isinstance(pairs[0], tuple):\n",
        "                pos_list, cause_list = zip(*pairs)\n",
        "                pos_list = list(pos_list)  # Convert pos_list to a list\n",
        "                cause_list = list(cause_list)  # Convert cause_list to a list\n",
        "                pairs = list(map(list, pairs))\n",
        "            else:\n",
        "                # Handle the case where there is only one emotion-cause pair\n",
        "                pos_list, cause_list = pairs\n",
        "                pos_list = [pos_list]  # Convert pos_list to a list\n",
        "                cause_list = [cause_list]  # Convert cause_list to a list\n",
        "                pairs = [list(pairs)]\n",
        "\n",
        "\n",
        "\n",
        "    # Continue with the rest of your code, using the 'pairs' variable as needed\n",
        "        pair_id_all.extend([doc_id * 10000 + p[0] * 100 + p[1] for p in pairs])\n",
        "\n",
        "        y_emotion_tmp, y_cause_tmp, y_pair_tmp, sen_len_tmp, x_tmp, distance_tmp = \\\n",
        "            np.zeros((max_doc_len, 2)), np.zeros((max_doc_len, 2)), np.zeros((max_doc_len * max_doc_len, 2)), \\\n",
        "            np.zeros((max_doc_len,)), np.zeros((max_doc_len, max_sen_len)), np.zeros((max_doc_len * max_doc_len,))\n",
        "\n",
        "        for i in range(d_len):\n",
        "            line = inputFile.readline().strip().split(',')\n",
        "            words = line[-1]\n",
        "            sen_len_tmp[i] = min(len(words.split()), max_sen_len)\n",
        "\n",
        "            for j, word in enumerate(words.split()):\n",
        "                word = word.lower()\n",
        "                if j >= max_sen_len:\n",
        "                    n_cut += 1\n",
        "                    break\n",
        "                elif word not in word_idx:\n",
        "                    x_tmp[i][j] = 0  # Change this to 0 for 'unknown' in the word_idx\n",
        "                else:\n",
        "                    x_tmp[i][j] = int(word_idx[word])\n",
        "\n",
        "        for i in range(d_len):\n",
        "            for j in range(d_len):\n",
        "                # Check whether i is an emotion clause\n",
        "                if i + 1 in pos_list:\n",
        "                    y_emotion_tmp[i][0] = 0\n",
        "                    y_emotion_tmp[i][1] = 1\n",
        "                else:\n",
        "                    y_emotion_tmp[i][0] = 1\n",
        "                    y_emotion_tmp[i][1] = 0\n",
        "\n",
        "                # Check whether j is a cause clause\n",
        "                if j + 1 in cause_list:\n",
        "                    y_cause_tmp[j][0] = 0\n",
        "                    y_cause_tmp[j][1] = 1\n",
        "                else:\n",
        "                    y_cause_tmp[j][0] = 1\n",
        "                    y_cause_tmp[j][1] = 0\n",
        "\n",
        "                # Check whether i, j clauses are emotion cause pairs\n",
        "                pair_id_curr = doc_id * 10000 + (i + 1) * 100 + (j + 1)\n",
        "                if pair_id_curr in pair_id_all:\n",
        "                    y_pair_tmp[i * max_doc_len + j][0] = 0\n",
        "                    y_pair_tmp[i * max_doc_len + j][1] = 1\n",
        "                else:\n",
        "                    y_pair_tmp[i * max_doc_len + j][0] = 1\n",
        "                    y_pair_tmp[i * max_doc_len + j][1] = 0\n",
        "\n",
        "                # Find the distance between the clauses, and use the same embedding beyond 10 clauses\n",
        "                distance_tmp[i * max_doc_len + j] = min(max(j - i + 100, 90), 110)\n",
        "\n",
        "        y_emotion.append(y_emotion_tmp)\n",
        "        y_cause.append(y_cause_tmp)\n",
        "        y_pair.append(y_pair_tmp)\n",
        "        x.append(x_tmp)\n",
        "        sen_len.append(sen_len_tmp)\n",
        "        doc_len.append(d_len)\n",
        "        distance.append(distance_tmp)\n",
        "\n",
        "    y_emotion, y_cause, y_pair, x, sen_len, doc_len, distance = map(torch.tensor, \\\n",
        "        [y_emotion, y_cause, y_pair, x, sen_len, doc_len, distance])\n",
        "\n",
        "    for var in ['y_emotion', 'y_cause', 'y_pair', 'x', 'sen_len', 'doc_len', 'distance']:\n",
        "        print('{}.shape {}'.format(var, eval(var).shape))\n",
        "    print('n_cut {}'.format(n_cut))\n",
        "    print('load data done!\\n')\n",
        "    return y_emotion, y_cause, y_pair, x, sen_len, doc_len, distance"
      ],
      "metadata": {
        "id": "16t8iXBAbtPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_file_path = 'clause_keywords.csv'          # clause keyword file\n",
        "# w2v_file = 'w2v_200.txt'                         # embedding file\n",
        "# max_sen_len = 30                                                    # max number of tokens per sentence\n",
        "# max_doc_len = 41\n",
        "# embedding_dim = 200                                                 # dimension of word embedding\n",
        "# embedding_dim_pos = 50\n",
        "\n",
        "# word_idx_rev, word_id_mapping, word_embedding, pos_embedding = load_w2v(\n",
        "#         embedding_dim, embedding_dim_pos, train_file_path, w2v_file)\n",
        "# word_embedding = torch.from_numpy(word_embedding)\n",
        "# train_file_name = 'fold1_train.txt'\n",
        "# ans = load_data_pair(train_file_name, word_id_mapping, max_doc_len, max_sen_len)\n",
        "# print(ans)"
      ],
      "metadata": {
        "id": "HF1Uxy0sDFTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi2oKBDsaj6-"
      },
      "source": [
        "E2E_PextE.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_failed_examples(failed_examples, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(failed_examples, f, indent=4)"
      ],
      "metadata": {
        "id": "0tI2DAwKsfG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7v8Kds9aKsg",
        "outputId": "499c8e1f-c0a4-47c5-bd56-910853f182d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2E_PextE(\n",
            "  (dropout1): Dropout(p=0.19999999999999996, inplace=False)\n",
            "  (dropout2): Dropout(p=0.0, inplace=False)\n",
            "  (dropout3): Dropout(p=0.0, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (pos_linear): Linear(in_features=200, out_features=2, bias=True)\n",
            "  (cause_linear): Linear(in_features=200, out_features=2, bias=True)\n",
            "  (pair_linear1): Linear(in_features=450, out_features=50, bias=True)\n",
            "  (pair_linear2): Linear(in_features=50, out_features=2, bias=True)\n",
            "  (word_bilstm): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
            "  (cause_bilstm): LSTM(202, 100, batch_first=True, bidirectional=True)\n",
            "  (pos_bilstm): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
            "  (attention): Attention(\n",
            "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (linear2): Linear(in_features=200, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Random i/o shapes x: torch.Size([32, 41, 30, 300]), distance: torch.Size([32, 1681, 50]), y_pos: torch.Size([32, 41, 2]), y_cause: torch.Size([32, 41, 2]), y_pair: torch.Size([32, 1681, 2])\n",
            "\n",
            "load embedding...\n",
            "w2v_file: ./data_combine_eng/ECF_glove_300.txt\n",
            "all_words: 0 hit_words: 0\n",
            "embedding.shape: (2, 300) embedding_pos.shape: (201, 50)\n",
            "load embedding done!\n",
            "\n",
            "############# fold 1 begin ###############\n",
            "load data_file: ./data_combine_eng/train.txt\n",
            "y_emotion.shape torch.Size([1001, 41, 2])\n",
            "y_cause.shape torch.Size([1001, 41, 2])\n",
            "y_pair.shape torch.Size([1001, 1681, 2])\n",
            "x.shape torch.Size([1001, 41, 30])\n",
            "sen_len.shape torch.Size([1001, 41])\n",
            "doc_len.shape torch.Size([1001])\n",
            "distance.shape torch.Size([1001, 1681])\n",
            "n_cut 0\n",
            "load data done!\n",
            "\n",
            "load data_file: ./data_combine_eng/dev.txt\n",
            "y_emotion.shape torch.Size([112, 41, 2])\n",
            "y_cause.shape torch.Size([112, 41, 2])\n",
            "y_pair.shape torch.Size([112, 1681, 2])\n",
            "x.shape torch.Size([112, 41, 30])\n",
            "sen_len.shape torch.Size([112, 41])\n",
            "doc_len.shape torch.Size([112])\n",
            "distance.shape torch.Size([112, 1681])\n",
            "n_cut 0\n",
            "load data done!\n",
            "\n",
            "Fold 1, Epoch 1, step 25: train loss 6.5811 \n",
            "emotion_predict: train acc 0.4643 p 0.0000 r 0.0000 f1 score 0.0000\n",
            "cause_predict: train acc 0.4911 p 0.5238 r 0.1897 f1 score 0.2785\n",
            "pair_predict: train acc 0.9402 p 0.0000 r 0.0000 f1 score 0.0000\n",
            "Fold 1 val loss 5.9578\n",
            "emotion_predict: val acc 0.5823 p 0.5823 r 1.0000 f1 0.7360\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.4995 p 0.5536 r 0.1115 f1 0.1856\n",
            "max_acc 0.4995 max_p 0.5536 max_r 0.1115 max_f1 0.1856\n",
            "\n",
            "pair_predict: val acc 0.9339 p 0.0000 r 0.0000 f1 0.0000\n",
            "max_acc 0.9339 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n",
            "\n",
            "avg max cause: max_acc 0.4995 max_p 0.5536 max_r 0.1115 max_f1 0.1856\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9339 max_p 0.0000 max_r 0.0000 max_f1 0.0000\n",
            "\n",
            "Fold 1, Epoch 2, step 25: train loss 4.4890 \n",
            "emotion_predict: train acc 0.5362 p 0.5221 r 0.9281 f1 score 0.6682\n",
            "cause_predict: train acc 0.5395 p 0.5000 r 0.3429 f1 score 0.4068\n",
            "pair_predict: train acc 0.9207 p 0.3388 r 0.5000 f1 score 0.4039\n",
            "Fold 1 val loss 5.1367\n",
            "emotion_predict: val acc 0.5823 p 0.5823 r 1.0000 f1 0.7360\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5179 p 0.5266 r 0.5701 f1 0.5475\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 3, step 25: train loss 4.3344 \n",
            "emotion_predict: train acc 0.5422 p 0.5254 r 0.9355 f1 score 0.6729\n",
            "cause_predict: train acc 0.5162 p 0.5165 r 0.3092 f1 score 0.3868\n",
            "pair_predict: train acc 0.9242 p 0.3669 r 0.5207 f1 score 0.4305\n",
            "Fold 1 val loss 5.0209\n",
            "emotion_predict: val acc 0.4177 p 0.0000 r 0.0000 f1 0.0000\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5179 p 0.5266 r 0.5701 f1 0.5475\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 4, step 25: train loss 5.0743 \n",
            "emotion_predict: train acc 0.5853 p 0.5880 r 0.9181 f1 score 0.7169\n",
            "cause_predict: train acc 0.4849 p 0.5000 r 0.1039 f1 score 0.1720\n",
            "pair_predict: train acc 0.9204 p 0.3846 r 0.4713 f1 score 0.4236\n",
            "Fold 1 val loss 4.8881\n",
            "emotion_predict: val acc 0.5823 p 0.5823 r 1.0000 f1 0.7360\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5041 p 0.5385 r 0.2140 f1 0.3063\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 5, step 25: train loss 4.2503 \n",
            "emotion_predict: train acc 0.5170 p 0.5170 r 1.0000 f1 score 0.6816\n",
            "cause_predict: train acc 0.5782 p 0.5556 r 0.2672 f1 score 0.3608\n",
            "pair_predict: train acc 0.9234 p 0.3810 r 0.6022 f1 score 0.4667\n",
            "Fold 1 val loss 4.8951\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.4885 p 0.0000 r 0.0000 f1 0.0000\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 6, step 25: train loss 4.5590 \n",
            "emotion_predict: train acc 0.5948 p 0.5948 r 1.0000 f1 score 0.7459\n",
            "cause_predict: train acc 0.5131 p 0.5594 r 0.4348 f1 score 0.4893\n",
            "pair_predict: train acc 0.9344 p 0.4140 r 0.5318 f1 score 0.4656\n",
            "Fold 1 val loss 4.8667\n",
            "emotion_predict: val acc 0.5823 p 0.5823 r 1.0000 f1 0.7360\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5143 p 0.5270 r 0.4910 f1 0.5084\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 7, step 25: train loss 4.8536 \n",
            "emotion_predict: train acc 0.5750 p 0.5750 r 1.0000 f1 score 0.7302\n",
            "cause_predict: train acc 0.4893 p 0.5556 r 0.2333 f1 score 0.3286\n",
            "pair_predict: train acc 0.9152 p 0.3857 r 0.4500 f1 score 0.4154\n",
            "Fold 1 val loss 4.8685\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5041 p 0.5385 r 0.2140 f1 0.3063\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 8, step 25: train loss 4.0862 \n",
            "emotion_predict: train acc 0.5461 p 0.5478 r 0.9085 f1 score 0.6835\n",
            "cause_predict: train acc 0.5033 p 0.5714 r 0.2250 f1 score 0.3229\n",
            "pair_predict: train acc 0.9312 p 0.3849 r 0.5598 f1 score 0.4561\n",
            "Fold 1 val loss 4.9035\n",
            "emotion_predict: val acc 0.5814 p 0.6028 r 0.8246 f1 0.6965\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5097 p 0.5271 r 0.4029 f1 0.4567\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 9, step 25: train loss 4.3375 \n",
            "emotion_predict: train acc 0.5417 p 0.5372 r 0.8503 f1 score 0.6584\n",
            "cause_predict: train acc 0.4750 p 0.5312 r 0.0890 f1 score 0.1525\n",
            "pair_predict: train acc 0.9347 p 0.3889 r 0.5166 f1 score 0.4437\n",
            "Fold 1 val loss 4.8520\n",
            "emotion_predict: val acc 0.4305 p 0.5714 r 0.0885 f1 0.1532\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5041 p 0.5385 r 0.2140 f1 0.3063\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 10, step 25: train loss 4.7622 \n",
            "emotion_predict: train acc 0.5260 p 0.5421 r 0.8325 f1 score 0.6566\n",
            "cause_predict: train acc 0.5573 p 0.6250 r 0.1124 f1 score 0.1905\n",
            "pair_predict: train acc 0.9314 p 0.3750 r 0.4848 f1 score 0.4229\n",
            "Fold 1 val loss 4.8543\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5041 p 0.5385 r 0.2140 f1 0.3063\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 11, step 25: train loss 4.4785 \n",
            "emotion_predict: train acc 0.5095 p 0.5095 r 1.0000 f1 score 0.6751\n",
            "cause_predict: train acc 0.4986 p 0.5217 r 0.3175 f1 score 0.3947\n",
            "pair_predict: train acc 0.9361 p 0.3651 r 0.5095 f1 score 0.4254\n",
            "Fold 1 val loss 4.8528\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5097 p 0.5352 r 0.3147 f1 0.3964\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 12, step 25: train loss 4.2259 \n",
            "emotion_predict: train acc 0.5539 p 0.5570 r 0.8980 f1 score 0.6875\n",
            "cause_predict: train acc 0.5019 p 0.5625 r 0.1304 f1 score 0.2118\n",
            "pair_predict: train acc 0.9275 p 0.3941 r 0.5579 f1 score 0.4619\n",
            "Fold 1 val loss 4.8488\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.4885 p 0.0000 r 0.0000 f1 0.0000\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 13, step 25: train loss 4.7283 \n",
            "emotion_predict: train acc 0.5876 p 0.5839 r 0.9400 f1 score 0.7203\n",
            "cause_predict: train acc 0.4774 p 0.4783 r 0.2431 f1 score 0.3223\n",
            "pair_predict: train acc 0.9251 p 0.3644 r 0.4640 f1 score 0.4082\n",
            "Fold 1 val loss 4.9631\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5041 p 0.5385 r 0.2140 f1 0.3063\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 14, step 25: train loss 4.9670 \n",
            "emotion_predict: train acc 0.5296 p 0.5412 r 0.8846 f1 score 0.6715\n",
            "cause_predict: train acc 0.5087 p 0.5238 r 0.2292 f1 score 0.3188\n",
            "pair_predict: train acc 0.9101 p 0.3728 r 0.4798 f1 score 0.4196\n",
            "Fold 1 val loss 4.8830\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.5097 p 0.5352 r 0.3147 f1 0.3964\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "Fold 1, Epoch 15, step 25: train loss 4.5545 \n",
            "emotion_predict: train acc 0.5125 p 0.5035 r 0.9177 f1 score 0.6502\n",
            "cause_predict: train acc 0.5531 p 0.5312 r 0.2313 f1 score 0.3223\n",
            "pair_predict: train acc 0.9266 p 0.3437 r 0.4977 f1 score 0.4067\n",
            "Fold 1 val loss 4.8443\n",
            "emotion_predict: val acc 0.5897 p 0.5959 r 0.9179 f1 0.7226\n",
            "max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "\n",
            "cause_predict: val acc 0.4995 p 0.5536 r 0.1115 f1 0.1856\n",
            "max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "\n",
            "pair_predict: val acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "avg max cause: max_acc 0.5179 max_p 0.5266 max_r 0.5701 max_f1 0.5475\n",
            "avg max pos: max_acc 0.5823 max_p 0.5823 max_r 1.0000 max_f1 0.7360\n",
            "avg max pair: max_acc 0.9171 max_p 0.3956 max_r 0.4821 max_f1 0.4346\n",
            "\n",
            "############# fold 1 end ###############\n",
            "\n",
            "cause_predict: val f1 in 10 fold: [[0.54749568]]\n",
            "average : acc 0.5179 p 0.5266 r 0.5701 f1 0.5475\n",
            "\n",
            "emotion_predict: val f1 in 10 fold: [[0.73604651]]\n",
            "average : acc 0.5823 p 0.5823 r 1.0000 f1 0.7360\n",
            "\n",
            "pair_predict: val f1 in 10 fold: [[0.43456291]]\n",
            "average : acc 0.9171 p 0.3956 r 0.4821 f1 0.4346\n",
            "\n"
          ]
        }
      ],
      "source": [
        "############################################ IMPORT ##########################################################\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "############################################ FLAGS ############################################################\n",
        "train_file_path = './data_combine_eng/clause_keywords.csv'          # clause keyword file\n",
        "w2v_file = './data_combine_eng/ECF_glove_300.txt'                         # embedding file\n",
        "embedding_dim = 300                                                 # dimension of word embedding\n",
        "embedding_dim_pos = 50                                              # dimension of position embedding\n",
        "max_sen_len = 30                                                    # max number of tokens per sentence\n",
        "max_doc_len = 41                                                    # max number of tokens per document\n",
        "n_hidden = 100                                                      # number of hidden unit\n",
        "n_class = 2                                                         # number of distinct class\n",
        "training_epochs = 15                                                # number of train epochs\n",
        "batch_size = 32                                                     # number of example per batch\n",
        "learning_rate = 0.0050                                              # learning rate\n",
        "keep_prob1 = 0.8                                                    # word embedding training dropout keep prob\n",
        "keep_prob2 = 1.0                                                    # softmax layer dropout keep prob\n",
        "keep_prob3 = 1.0                                                    # softmax layer dropout keep prob\n",
        "l2_reg = 0.00010                                                    # l2 regularization\n",
        "cause = 1.0                                                         # lambda1\n",
        "pos = 1.0                                                           # lambda2\n",
        "pair = 2.5                                                          # lambda3\n",
        "diminish_factor = 0.400                                             # give less weight to -ve examples\n",
        "\n",
        "############################################ MODEL ############################################################\n",
        "class E2E_PextE(nn.Module):\n",
        "    def __init__(self, embedding_dim, embedding_dim_pos, sen_len, doc_len, keep_prob1, keep_prob2, \\\n",
        "                 keep_prob3, n_hidden, n_class):\n",
        "        super(E2E_PextE, self).__init__()\n",
        "        self.embedding_dim = embedding_dim; self.embedding_dim_pos = embedding_dim_pos\n",
        "        self.sen_len = sen_len; self.doc_len = doc_len\n",
        "        self.keep_prob1 = keep_prob1; self.keep_prob2 = keep_prob2\n",
        "        self.n_hidden = n_hidden; self.n_class = n_class\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p = 1 - keep_prob1)\n",
        "        self.dropout2 = nn.Dropout(p = 1 - keep_prob2)\n",
        "        self.dropout3 = nn.Dropout(p = 1 - keep_prob3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pos_linear = nn.Linear(2*n_hidden, n_class)\n",
        "        self.cause_linear = nn.Linear(2*n_hidden, n_class)\n",
        "        self.pair_linear1 = nn.Linear(4*n_hidden + embedding_dim_pos, n_hidden//2)\n",
        "        self.pair_linear2 = nn.Linear(n_hidden//2, n_class)\n",
        "        self.word_bilstm = nn.LSTM(embedding_dim, n_hidden, batch_first = True, bidirectional = True)\n",
        "        self.cause_bilstm = nn.LSTM(2*n_hidden + n_class, n_hidden, batch_first = True, bidirectional = True)\n",
        "        self.pos_bilstm = nn.LSTM(2*n_hidden, n_hidden, batch_first = True, bidirectional = True)\n",
        "        self.attention = Attention(n_hidden, sen_len)\n",
        "\n",
        "    def get_clause_embedding(self, x):\n",
        "        '''\n",
        "        input shape: [batch_size, doc_len, sen_len, embedding_dim]\n",
        "        output shape: [batch_size, doc_len, 2 * n_hidden]\n",
        "        '''\n",
        "        x = x.reshape(-1, self.sen_len, self.embedding_dim)\n",
        "        x = self.dropout1(x)\n",
        "        # x is of shape (batch_size * max_doc_len, max_sen_len, embedding_dim)\n",
        "        x, hidden_states = self.word_bilstm(x.float())\n",
        "        # x is of shape (batch_size * max_doc_len, max_sen_len, 2 * n_hidden)\n",
        "        s = self.attention(x).reshape(-1, self.doc_len, 2 * self.n_hidden)\n",
        "        # s is of shape (batch_size, max_doc_len, 2 * n_hidden)\n",
        "        return s\n",
        "\n",
        "    def get_emotion_prediction(self, x):\n",
        "        '''\n",
        "        input shape: [batch_size, doc_len, 2 * n_hidden]\n",
        "        output(s) shape: [batch_size, doc_len, 2 * n_hidden], [batch_size, doc_len, n_class]\n",
        "        '''\n",
        "        x_context, hidden_states = self.pos_bilstm(x.float())\n",
        "        # x_context is of shape (batch_size, max_doc_len, 2 * n_hidden)\n",
        "        x = x_context.reshape(-1, 2 * self.n_hidden)\n",
        "        x = self.dropout2(x)\n",
        "        # x is of shape (batch_size * max_doc_len, 2 * n_hidden)\n",
        "        pred_pos = F.softmax(self.pos_linear(x), dim = -1)\n",
        "        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n",
        "        pred_pos = pred_pos.reshape(-1, self.doc_len, self.n_class)\n",
        "        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n",
        "        return x_context, pred_pos\n",
        "\n",
        "    def get_cause_prediction(self, x):\n",
        "        '''\n",
        "        input shape: [batch_size, doc_len, 2 * n_hidden + n_class]\n",
        "        output(s) shape: [batch_size, doc_len, 2 * n_hidden], [batch_size, doc_len, n_class]\n",
        "        '''\n",
        "        x_context, hidden_states = self.cause_bilstm(x.float())\n",
        "        # x_context is of shape (batch_size, max_doc_len, 2 * n_hidden)\n",
        "        x = x_context.reshape(-1, 2 * self.n_hidden)\n",
        "        x = self.dropout2(x)\n",
        "        # x is of shape (batch_size * max_doc_len, 2 * n_hidden)\n",
        "        pred_cause = F.softmax(self.cause_linear(x), dim = -1)\n",
        "        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n",
        "        pred_cause = pred_cause.reshape(-1, self.doc_len, self.n_class)\n",
        "        # pred_pos is of shape (batch_size * max_doc_len, n_class)\n",
        "        return x_context, pred_cause\n",
        "\n",
        "    def get_pair_prediction(self, x1, x2, distance):\n",
        "        '''\n",
        "        input(s) shape: [batch_size * doc_len, 2 * n_hidden], [batch_size * doc_len, 2 * n_hidden],\n",
        "                        [batch_size, doc_len * doc_len, embedding_dim_pos]\n",
        "        output shape: [batch_size, doc_len * doc_len, n_class]\n",
        "        '''\n",
        "        x = create_pairs(x1, x2)\n",
        "        # x is of shape (batch_size, max_doc_len * max_doc_len, 4 * n_hidden)\n",
        "        x_distance = torch.cat([x, distance.float()], -1)\n",
        "        # x_distance is of shape (batch_size, max_doc_len * max_doc_len, 4 * n_hidden + embedding_dim_pos)\n",
        "        x_distance = x_distance.reshape(-1, 4 * self.n_hidden + self.embedding_dim_pos)\n",
        "        x_distance = self.dropout3(x_distance)\n",
        "        # x is of shape (batch_size * max_doc_len * max_doc_len, 4 * n_hidden + embedding_dim_pos)\n",
        "        pred_pair = F.softmax(self.pair_linear2(self.relu(self.pair_linear1(x_distance))), dim = -1)\n",
        "        # pred_pair is of shape (batch_size * max_doc_len * max_doc_len, n_class)\n",
        "        pred_pair = pred_pair.reshape(-1, self.doc_len * self.doc_len, self.n_class)\n",
        "        # pred_pair is of shape (batch_size, max_doc_len * max_doc_len, n_class)\n",
        "        return pred_pair\n",
        "\n",
        "    def forward(self, x, distance):\n",
        "        '''\n",
        "        input(s) shape: [batch_size, doc_len, sen_len, embedding_dim],\n",
        "                        [batch_size, doc_len * doc_len, embedding_dim_pos]\n",
        "        output(s) shape: [batch_size, doc_len, n_class], [batch_size, doc_len, n_class],\n",
        "                         [batch_size, doc_len * doc_len, n_class]\n",
        "        '''\n",
        "        s = self.get_clause_embedding(x)\n",
        "        x_pos, pred_pos = self.get_emotion_prediction(s)\n",
        "        s_pred_pos = torch.cat([s, pred_pos], 2)\n",
        "        x_cause, pred_cause = self.get_cause_prediction(s_pred_pos)\n",
        "        pred_pair = self.get_pair_prediction(x_pos, x_cause, distance)\n",
        "        return pred_pos, pred_cause, pred_pair\n",
        "\n",
        "############################################ TRAIN #####################################################\n",
        "def train_and_eval(Model, pos_cause_criterion, pair_criterion, optimizer):\n",
        "    word_idx_rev, word_id_mapping, word_embedding, pos_embedding = load_w2v(\n",
        "        embedding_dim, embedding_dim_pos, train_file_path, w2v_file)\n",
        "    word_embedding = torch.from_numpy(word_embedding)\n",
        "    # Train distance embeddings\n",
        "    pos_embedding = torch.autograd.Variable(torch.from_numpy(pos_embedding))\n",
        "    pos_embedding.requires_grad_(True)\n",
        "    torch.save(word_embedding, './save/word_embedding.pth')\n",
        "    torch.save(word_id_mapping, './save/word_id_mapping.pth')\n",
        "    acc_cause_list, p_cause_list, r_cause_list, f1_cause_list = [], [], [], []\n",
        "    acc_pos_list, p_pos_list, r_pos_list, f1_pos_list = [], [], [], []\n",
        "    acc_pair_list, p_pair_list, r_pair_list, f1_pair_list = [], [], [], []\n",
        "    #################################### LOOP OVER FOLDS ####################################\n",
        "    for fold in range(1, 2):\n",
        "        print('############# fold {} begin ###############'.format(fold))\n",
        "        ############################# RE-INITIALIZE MODEL PARAMETERS #############################\n",
        "        for layer in Model.parameters():\n",
        "            nn.init.uniform_(layer.data, -0.10, 0.10)\n",
        "        #################################### TRAIN/TEST DATA ####################################\n",
        "        train_file_name = 'train.txt'.format(fold)\n",
        "        val_file_name = 'dev.txt'.format(fold)\n",
        "        tr_y_position, tr_y_cause, tr_y_pair, tr_x, tr_sen_len, tr_doc_len, tr_distance = load_data_pair(\n",
        "                        './data_combine_eng/'+train_file_name, word_id_mapping, max_doc_len, max_sen_len)\n",
        "        val_y_position, val_y_cause, val_y_pair, val_x, val_sen_len, val_doc_len, val_distance = \\\n",
        "            load_data_pair('./data_combine_eng/'+val_file_name, word_id_mapping, max_doc_len, max_sen_len)\n",
        "        max_f1_cause, max_f1_pos, max_f1_pair, max_f1_avg = [-1.] * 4\n",
        "        #################################### LOOP OVER EPOCHS ####################################\n",
        "        for epoch in range(1, training_epochs + 1):\n",
        "            step = 1\n",
        "            #################################### GET BATCH DATA ####################################\n",
        "            for train, _ in get_batch_data_pair(\n",
        "                tr_x, tr_sen_len, tr_doc_len, tr_y_position, tr_y_cause, tr_y_pair, tr_distance, batch_size):\n",
        "                tr_x_batch, tr_sen_len_batch, tr_doc_len_batch, tr_true_y_pos, tr_true_y_cause, \\\n",
        "                tr_true_y_pair, tr_distance_batch = train\n",
        "                Model.train()\n",
        "                tr_pred_y_pos, tr_pred_y_cause, tr_pred_y_pair = Model(embedding_lookup(word_embedding, \\\n",
        "                tr_x_batch), embedding_lookup(pos_embedding, tr_distance_batch))\n",
        "                ############################## LOSS FUNCTION AND OPTIMIZATION ##############################\n",
        "                loss = pos_cause_criterion(tr_true_y_pos, tr_pred_y_pos, tr_doc_len_batch)*pos + \\\n",
        "                pos_cause_criterion(tr_true_y_cause, tr_pred_y_cause, tr_doc_len_batch)*cause + \\\n",
        "                pair_criterion(tr_true_y_pair, tr_pred_y_pair, tr_doc_len_batch)*pair\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                #################################### PRINT AFTER EPOCHS ####################################\n",
        "                if step % 25 == 0:\n",
        "                    # print(Model.pair_linear.weight.shape); print(Model.pair_linear.weight.grad)\n",
        "                    print('Fold {}, Epoch {}, step {}: train loss {:.4f} '.format(fold, epoch, step, loss))\n",
        "                    acc, p, r, f1 = acc_prf_aux(tr_pred_y_pos, tr_true_y_pos, tr_doc_len_batch)\n",
        "                    print('emotion_predict: train acc {:.4f} p {:.4f} r {:.4f} f1 score {:.4f}'.format(\n",
        "                            acc, p, r, f1))\n",
        "                    acc, p, r, f1 = acc_prf_aux(tr_pred_y_cause, tr_true_y_cause, tr_doc_len_batch)\n",
        "                    print('cause_predict: train acc {:.4f} p {:.4f} r {:.4f} f1 score {:.4f}'.format(\n",
        "                            acc, p, r, f1))\n",
        "                    acc, p, r, f1 = acc_prf_pair(tr_pred_y_pair, tr_true_y_pair, tr_doc_len_batch)\n",
        "                    print('pair_predict: train acc {:.4f} p {:.4f} r {:.4f} f1 score {:.4f}'.format(\n",
        "                            acc, p, r, f1))\n",
        "                step += 1\n",
        "            #################################### TEST ON 1 FOLD ####################################\n",
        "            with torch.no_grad():\n",
        "                Model.eval()\n",
        "                val_pred_y_pos, val_pred_y_cause, val_pred_y_pair = Model(embedding_lookup(word_embedding, \\\n",
        "                val_x), embedding_lookup(pos_embedding, val_distance))\n",
        "\n",
        "                loss = pos_cause_criterion(val_y_position, val_pred_y_pos, val_doc_len)*pos + \\\n",
        "                pos_cause_criterion(val_y_cause, val_pred_y_cause, val_doc_len)*cause + \\\n",
        "                pair_criterion(val_y_pair, val_pred_y_pair, val_doc_len)*pair\n",
        "                print('Fold {} val loss {:.4f}'.format(fold, loss))\n",
        "                acc, p, r, f1 = acc_prf_aux(val_pred_y_pos, val_y_position, val_doc_len)\n",
        "                result_avg_pos = [acc, p, r, f1]\n",
        "                if f1 > max_f1_pos:\n",
        "                    max_acc_pos, max_p_pos, max_r_pos, max_f1_pos = acc, p, r, f1\n",
        "                print('emotion_predict: val acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc, p, r, f1))\n",
        "                print('max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n",
        "                    max_acc_pos, max_p_pos, max_r_pos, max_f1_pos))\n",
        "\n",
        "                acc, p, r, f1 = acc_prf_aux(val_pred_y_cause, val_y_cause, val_doc_len)\n",
        "                result_avg_cause = [acc, p, r, f1]\n",
        "                if f1 > max_f1_cause:\n",
        "                    max_acc_cause, max_p_cause, max_r_cause, max_f1_cause = acc, p, r, f1\n",
        "                print('cause_predict: val acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc, p, r, f1))\n",
        "                print('max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n",
        "                    max_acc_cause, max_p_cause, max_r_cause, max_f1_cause))\n",
        "\n",
        "                acc, p, r, f1 = acc_prf_pair(val_pred_y_pair, val_y_pair, val_doc_len)\n",
        "                result_avg_pair = [acc, p, r, f1]\n",
        "                if f1 > max_f1_pair:\n",
        "                    max_acc_pair, max_p_pair, max_r_pair, max_f1_pair = acc, p, r, f1\n",
        "                print('pair_predict: val acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc, p, r, f1))\n",
        "                print('max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n",
        "                    max_acc_pair, max_p_pair, max_r_pair, max_f1_pair))\n",
        "\n",
        "            #################################### STORE BETTER PAIR F1 ####################################\n",
        "            if result_avg_pair[-1] > max_f1_avg:\n",
        "                torch.save(pos_embedding, \"./save/pos_embedding.pth\".format(fold))\n",
        "                torch.save(Model.state_dict(), \"./save/E2E-PextE.pth\".format(fold))\n",
        "                max_f1_avg = result_avg_pair[-1]\n",
        "                result_avg_cause_max = result_avg_cause\n",
        "                result_avg_pos_max = result_avg_pos\n",
        "                result_avg_pair_max = result_avg_pair\n",
        "\n",
        "            print('avg max cause: max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}'.format(\n",
        "                result_avg_cause_max[0], result_avg_cause_max[1], result_avg_cause_max[2], result_avg_cause_max[3]))\n",
        "            print('avg max pos: max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}'.format(\n",
        "                result_avg_pos_max[0], result_avg_pos_max[1], result_avg_pos_max[2], result_avg_pos_max[3]))\n",
        "            print('avg max pair: max_acc {:.4f} max_p {:.4f} max_r {:.4f} max_f1 {:.4f}\\n'.format(\n",
        "                result_avg_pair_max[0], result_avg_pair_max[1], result_avg_pair_max[2], result_avg_pair_max[3]))\n",
        "\n",
        "        print('############# fold {} end ###############'.format(fold))\n",
        "        acc_cause_list.append(result_avg_cause_max[0])\n",
        "        p_cause_list.append(result_avg_cause_max[1])\n",
        "        r_cause_list.append(result_avg_cause_max[2])\n",
        "        f1_cause_list.append(result_avg_cause_max[3])\n",
        "        acc_pos_list.append(result_avg_pos_max[0])\n",
        "        p_pos_list.append(result_avg_pos_max[1])\n",
        "        r_pos_list.append(result_avg_pos_max[2])\n",
        "        f1_pos_list.append(result_avg_pos_max[3])\n",
        "        acc_pair_list.append(result_avg_pair_max[0])\n",
        "        p_pair_list.append(result_avg_pair_max[1])\n",
        "        r_pair_list.append(result_avg_pair_max[2])\n",
        "        f1_pair_list.append(result_avg_pair_max[3])\n",
        "\n",
        "    #################################### FINAL TEST RESULTS ON 10 FOLDS ####################################\n",
        "    all_results = [acc_cause_list, p_cause_list, r_cause_list, f1_cause_list, \\\n",
        "    acc_pos_list, p_pos_list, r_pos_list, f1_pos_list, acc_pair_list, p_pair_list, r_pair_list, f1_pair_list,]\n",
        "    acc_cause, p_cause, r_cause, f1_cause, acc_pos, p_pos, r_pos, f1_pos, acc_pair, p_pair, r_pair, f1_pair = \\\n",
        "        map(lambda x: np.array(x).mean(), all_results)\n",
        "    print('\\ncause_predict: val f1 in 10 fold: {}'.format(np.array(f1_cause_list).reshape(-1,1)))\n",
        "    print('average : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}\\n'.format(acc_cause, p_cause, r_cause, f1_cause))\n",
        "    print('emotion_predict: val f1 in 10 fold: {}'.format(np.array(f1_pos_list).reshape(-1,1)))\n",
        "    print('average : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}\\n'.format(acc_pos, p_pos, r_pos, f1_pos))\n",
        "    print('pair_predict: val f1 in 10 fold: {}'.format(np.array(f1_pair_list).reshape(-1,1)))\n",
        "    print('average : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}\\n'.format(acc_pair, p_pair, r_pair, f1_pair))\n",
        "\n",
        "############################################### MAIN ########################################################\n",
        "def main():\n",
        "    Model = E2E_PextE(embedding_dim, embedding_dim_pos, max_sen_len, max_doc_len, \\\n",
        "    keep_prob1, keep_prob2, keep_prob3, n_hidden, n_class)\n",
        "    Model.to(device)\n",
        "    print(Model)\n",
        "    x = torch.rand([batch_size, max_doc_len, max_sen_len, embedding_dim]).to(device)\n",
        "    distance = torch.rand([batch_size, max_doc_len * max_doc_len, embedding_dim_pos]).to(device)\n",
        "    pred_pos, pred_cause, pred_pair = Model(x, distance)\n",
        "    print(\"Random i/o shapes x: {}, distance: {}, y_pos: {}, y_cause: {}, y_pair: {}\".format(\n",
        "        x.shape, distance.shape, pred_pos.shape, pred_cause.shape, pred_pair.shape))\n",
        "    pos_cause_criterion = ce_loss_aux(); pair_criterion = ce_loss_pair(diminish_factor)\n",
        "    optimizer = optim.Adam(Model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "    train_and_eval(Model, pos_cause_criterion, pair_criterion, optimizer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test code"
      ],
      "metadata": {
        "id": "lb2_8Y-04RiL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdsj2bY2aHE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593bb2af-329d-4ec5-8668-bab7e58b1138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# fold 1 begin ###############\n",
            "load data_file: ./data_combine_eng/test.txt\n",
            "y_emotion.shape torch.Size([261, 41, 2])\n",
            "y_cause.shape torch.Size([261, 41, 2])\n",
            "y_pair.shape torch.Size([261, 1681, 2])\n",
            "x.shape torch.Size([261, 41, 30])\n",
            "sen_len.shape torch.Size([261, 41])\n",
            "doc_len.shape torch.Size([261])\n",
            "distance.shape torch.Size([261, 1681])\n",
            "n_cut 0\n",
            "load data done!\n",
            "\n",
            "Fold 1 emotion acc: 0.5320 p: 0.5320 r: 1.0000 f1: 0.6945\n",
            "Fold 1 cause acc: 0.5136 p: 0.5029 r: 0.5581 f1: 0.5291\n",
            "Fold 1 pair acc: 0.9248 p: 0.3804 r: 0.5137 f1:0.4371\n",
            "############# fold 1 end ###############\n",
            "\n",
            "\n",
            "cause_predict: test f1 in 10 fold: [[0.5290566]]\n",
            "\n",
            "average : acc 0.5136 p 0.5029 r 0.5581 f1 0.5291\n",
            "\n",
            "emotion_predict: test f1 in 10 fold: [[0.69447978]]\n",
            "\n",
            "average : acc 0.5320 p 0.5320 r 1.0000 f1 0.6945\n",
            "\n",
            "pair_predict: test f1 in 10 fold: [[0.43708016]]\n",
            "\n",
            "average : acc 0.9248 p 0.3804 r 0.5137 f1 0.4371\n"
          ]
        }
      ],
      "source": [
        "\n",
        "############################################ IMPORT ##########################################################\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "############################################ FLAGS ############################################################\n",
        "train_file_path = './data_combine_eng/clause_keywords.csv'          # clause keyword file\n",
        "w2v_file = 'data_combine_eng/ECF_glove_300.txt'                         # embedding file\n",
        "embedding_dim = 300                                                 # dimension of word embedding\n",
        "embedding_dim_pos = 50                                              # dimension of position embedding\n",
        "max_sen_len = 30                                                    # max number of tokens per sentence\n",
        "max_doc_len = 41                                                    # max number of tokens per document\n",
        "n_hidden = 100                                                      # number of hidden unit\n",
        "n_class = 2                                                         # number of distinct class\n",
        "keep_prob1 = 0.8                                                    # word embedding training dropout keep prob\n",
        "keep_prob2 = 1.0                                                    # softmax layer dropout keep prob\n",
        "keep_prob3 = 1.0                                                    # softmax layer dropout keep prob\n",
        "\n",
        "################################################ TEST #########################################################\n",
        "def test(Model):\n",
        "    word_embedding = torch.load(\"./save/word_embedding.pth\")\n",
        "    word_id_mapping = torch.load(\"./save/word_id_mapping.pth\")\n",
        "    acc_cause_list, p_cause_list, r_cause_list, f1_cause_list = [], [], [], []\n",
        "    acc_pos_list, p_pos_list, r_pos_list, f1_pos_list = [], [], [], []\n",
        "    acc_pair_list, p_pair_list, r_pair_list, f1_pair_list = [], [], [], []\n",
        "    #################################### LOOP OVER FOLDS ####################################\n",
        "    for fold in range(1, 2):\n",
        "        print('############# fold {} begin ###############'.format(fold))\n",
        "        #################################### LOAD TEST DATA ####################################\n",
        "        test_file_name = 'test.txt'.format(fold)\n",
        "        te_y_position, te_y_cause, te_y_pair, te_x, te_sen_len, te_doc_len, te_distance = load_data_pair(\n",
        "            './data_combine_eng/'+test_file_name, word_id_mapping, max_doc_len, max_sen_len)\n",
        "        pos_embedding = torch.load(\"./save/pos_embedding.pth\".format(fold))\n",
        "        Model.load_state_dict(torch.load(\"./save/E2E-PextE.pth\".format(fold)))\n",
        "        with torch.no_grad():\n",
        "            Model.eval()\n",
        "            te_pred_y_pos, te_pred_y_cause, te_pred_y_pair = Model(embedding_lookup(word_embedding, \\\n",
        "                te_x), embedding_lookup(pos_embedding, te_distance))\n",
        "            # emotion results\n",
        "            acc, p, r, f1 = acc_prf_aux(te_pred_y_pos, te_y_position, te_doc_len)\n",
        "            acc_pos_list.append(acc); p_pos_list.append(p); r_pos_list.append(r); f1_pos_list.append(f1)\n",
        "            print(\"Fold {} emotion acc: {:.4f} p: {:.4f} r: {:.4f} f1: {:.4f}\".format(fold, acc, p, r, f1))\n",
        "            # cause results\n",
        "            acc, p, r, f1 = acc_prf_aux(te_pred_y_cause, te_y_cause, te_doc_len)\n",
        "            acc_cause_list.append(acc); p_cause_list.append(p); r_cause_list.append(r); f1_cause_list.append(f1)\n",
        "            print(\"Fold {} cause acc: {:.4f} p: {:.4f} r: {:.4f} f1: {:.4f}\".format(fold, acc, p, r, f1))\n",
        "            # pair results\n",
        "            acc, p, r, f1 = acc_prf_pair(te_pred_y_pair, te_y_pair, te_doc_len)\n",
        "            acc_pair_list.append(acc); p_pair_list.append(p); r_pair_list.append(r); f1_pair_list.append(f1)\n",
        "            print(\"Fold {} pair acc: {:.4f} p: {:.4f} r: {:.4f} f1:{:.4f}\".format(fold, acc, p, r, f1))\n",
        "\n",
        "        print('############# fold {} end ###############\\n'.format(fold))\n",
        "\n",
        "    #################################### FINAL TEST RESULTS ON 10 FOLDS ####################################\n",
        "    all_results = [acc_cause_list, p_cause_list, r_cause_list, f1_cause_list, \\\n",
        "    acc_pos_list, p_pos_list, r_pos_list, f1_pos_list, acc_pair_list, p_pair_list, r_pair_list, f1_pair_list,]\n",
        "    acc_cause, p_cause, r_cause, f1_cause, acc_pos, p_pos, r_pos, f1_pos, acc_pair, p_pair, r_pair, f1_pair = \\\n",
        "        map(lambda x: np.array(x).mean(), all_results)\n",
        "    print('\\ncause_predict: test f1 in 10 fold: {}'.format(np.array(f1_cause_list).reshape(-1,1)))\n",
        "    print('\\naverage : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc_cause, p_cause, r_cause, f1_cause))\n",
        "    print('\\nemotion_predict: test f1 in 10 fold: {}'.format(np.array(f1_pos_list).reshape(-1,1)))\n",
        "    print('\\naverage : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc_pos, p_pos, r_pos, f1_pos))\n",
        "    print('\\npair_predict: test f1 in 10 fold: {}'.format(np.array(f1_pair_list).reshape(-1,1)))\n",
        "    print('\\naverage : acc {:.4f} p {:.4f} r {:.4f} f1 {:.4f}'.format(acc_pair, p_pair, r_pair, f1_pair))\n",
        "\n",
        "############################################### MAIN ########################################################\n",
        "def main():\n",
        "    Model = E2E_PextE(embedding_dim, embedding_dim_pos, max_sen_len, max_doc_len, \\\n",
        "    keep_prob1, keep_prob2, keep_prob3, n_hidden, n_class).to(device)\n",
        "    test(Model)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aJbSLFC75QqY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpVzpagadBHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aRgNTF-Mc54d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}